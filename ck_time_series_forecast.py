import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from clickhouse_driver import Client
from darts import TimeSeries
from darts.models import Prophet, ARIMA, ExponentialSmoothing, XGBModel, LightGBMModel, CatBoostModel, LinearRegressionModel, RandomForest
from darts.metrics import mape, rmse, mae
from sklearn.ensemble import VotingRegressor
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.family'] = ['Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è¿æ¥åˆ°ClickHouse
def connect_clickhouse(host='localhost', port=9000, user='default', password='', database='default'):
    """è¿æ¥åˆ°ClickHouseæ•°æ®åº“"""
    try:
        client = Client(
            host=host,
            port=port,
            user=user,
            password=password,
            database=database,
            connect_timeout=10,
            send_receive_timeout=30
        )
        # æµ‹è¯•è¿æ¥
        result = client.execute('SELECT 1')
        print(f"æˆåŠŸè¿æ¥åˆ°ClickHouse: {host}:{port}")
        return client
    except Exception as e:
        print(f"è¿æ¥ClickHouseå¤±è´¥: {e}")
        print(f"å°è¯•è¿æ¥çš„åœ°å€: {host}:{port}")
        print("è¯·æ£€æŸ¥:")
        print("1. ç«¯å£æ˜¯å¦æ­£ç¡® (é€šå¸¸ä¸º 9000)")
        print("2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("3. ClickHouse æœåŠ¡æ˜¯å¦è¿è¡Œ")
        print("4. é˜²ç«å¢™è®¾ç½®")
        return None

# ä»ClickHouseè¯»å–æ•°æ®
def fetch_data_from_clickhouse(client, target_date, table_name):
    """
    ä»ClickHouseè¯»å–æŒ‡å®šæ—¥æœŸçš„æŒ‡æ ‡æ•°æ®
    æ•°æ®åº”åŒ…å«timeå’Œvalueå­—æ®µï¼Œæ¯5åˆ†é’Ÿä¸€ä¸ªæ•°æ®ç‚¹
    """
    if not client:
        return None
    
    # æ„å»ºæŸ¥è¯¢æ—¥æœŸèŒƒå›´ (ä¸€æ•´å¤©)
    start_date = f"{target_date} 00:00:00"
    end_date = f"{target_date} 23:59:59"
    
    # æŸ¥è¯¢è¯­å¥ - è¯·æ ¹æ®å®é™…è¡¨ç»“æ„å’Œå­—æ®µåè°ƒæ•´
    query = f"""
    select time,value from tb_metric_raw where code ='tps' and ci_id ='000000000020571d' order by time asc; 
    """
    
    try:
        # æ‰§è¡ŒæŸ¥è¯¢
        result = client.execute(query)
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(result, columns=['time', 'value'])
        df['time'] = pd.to_datetime(df['time'])
        
        print(f"æˆåŠŸè¯»å–æ•°æ®: {len(df)} æ¡è®°å½•")
        print(f"æ—¶é—´èŒƒå›´: {df['time'].min()} è‡³ {df['time'].max()}")
        
        return df
    except Exception as e:
        print(f"è¯»å–æ•°æ®å¤±è´¥: {e}")
        return None

# å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®
def prepare_time_series(df):
    """å°†DataFrameè½¬æ¢ä¸ºDartsçš„TimeSerieså¯¹è±¡"""
    # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
    df = df.sort_values('time')
    
    # åˆ›å»ºTimeSerieså¯¹è±¡
    series = TimeSeries.from_dataframe(
        df,
        time_col='time',
        value_cols='value',
        freq='5T'  # 5åˆ†é’Ÿé¢‘ç‡
    )
    
    return series

# æ‹†åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
def split_train_validation(series, train_ratio=0.8):
    """å°†æ—¶é—´åºåˆ—æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†"""
    train_size = int(len(series) * train_ratio)
    train, val = series[:train_size], series[train_size:]
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(train)} ä¸ªæ•°æ®ç‚¹")
    print(f"éªŒè¯é›†å¤§å°: {len(val)} ä¸ªæ•°æ®ç‚¹")
    
    return train, val

# è®­ç»ƒæ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹
def train_and_forecast(train, val):
    """è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹"""
    # åˆå§‹åŒ–æ¨¡å‹
    models = {
        # ç»Ÿè®¡å­¦ä¹ æ¨¡å‹
        "Prophet": Prophet(daily_seasonality=True, weekly_seasonality=False, yearly_seasonality=False),
        "ARIMA": ARIMA(p=2, d=1, q=2),
        "Exponential Smoothing": ExponentialSmoothing(seasonal_periods=24),
        
        # æœºå™¨å­¦ä¹ æ¨¡å‹
        "XGBoost": XGBModel(
            lags=24, # è®¾ç½®æ»åé¡¹ï¼Œå¯ä»¥æ˜¯ä¸€ä¸ªæ•´æ•°æˆ–åˆ—è¡¨
            output_chunk_length=1,
            random_state=42
        ),
        "LightGBM": LightGBMModel(
            lags=24,
            output_chunk_length=1,
            random_state=42,
            verbose=-1
        ),
        "CatBoost": CatBoostModel(
            lags=4,
            output_chunk_length=1,
            random_state=42,
            verbose=False
        ),
        "Random Forest": RandomForest(
            lags=24,
            output_chunk_length=1,
            random_state=42,
            n_estimators=100
        ),
        "Linear Regression": LinearRegressionModel(
            lags=24,
            output_chunk_length=1
        )
    }
    
    results = {}
    forecasts = {}
    
    # è®­ç»ƒæ¯ä¸ªæ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹
    for name, model in models.items():
        print(f"\nè®­ç»ƒ {name} æ¨¡å‹...")
        
        try:
            # è®­ç»ƒæ¨¡å‹
            model.fit(train)
            
            # è¿›è¡Œé¢„æµ‹
            forecast = model.predict(len(val))
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            model_mape = mape(val, forecast)
            model_rmse = rmse(val, forecast)
            model_mae = mae(val, forecast)
            
            print(f"{name} æ¨¡å‹è¯„ä¼°:")
            print(f"  MAPE: {model_mape:.2f}%")
            print(f"  RMSE: {model_rmse:.2f}")
            print(f"  MAE: {model_mae:.2f}")
            
            results[name] = {
                "model": model,
                "forecast": forecast,
                "mape": model_mape,
                "rmse": model_rmse,
                "mae": model_mae
            }
            
            forecasts[name] = forecast
            
        except Exception as e:
            print(f"{name} æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            continue
    
    return results, forecasts

# å®ç°é›†æˆå­¦ä¹ 
def ensemble_forecast(forecasts, val, method='average'):
    """
    é›†æˆå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
    method: 'average', 'weighted_average', 'median'
    """
    if not forecasts:
        return None
    
    # è¿‡æ»¤æ‰ç©ºçš„é¢„æµ‹ç»“æœ
    valid_forecasts = {name: fcst for name, fcst in forecasts.items() if fcst is not None}
    
    if not valid_forecasts:
        return None, None, None, None
        
    forecast_values = []
    model_names = []
    
    for name, forecast in valid_forecasts.items():
        # ç¡®ä¿æ‰€æœ‰é¢„æµ‹ç»“æœçš„é•¿åº¦ç›¸åŒ
        if len(forecast) == len(val):
            forecast_values.append(forecast.values().flatten())
            model_names.append(name)
        else:
            print(f"è­¦å‘Š: æ¨¡å‹ {name} çš„é¢„æµ‹é•¿åº¦ä¸éªŒè¯é›†ä¸åŒ¹é…ï¼Œè·³è¿‡é›†æˆ")
            
    if not forecast_values:
        return None, None, None, None
        
    forecast_array = np.array(forecast_values)
    
    if method == 'average':
        # ç®€å•å¹³å‡
        ensemble_values = np.mean(forecast_array, axis=0)
    elif method == 'weighted_average':
        # åŸºäºMAPEçš„åŠ æƒå¹³å‡ï¼ˆMAPEè¶Šå°æƒé‡è¶Šå¤§ï¼‰
        weights = []
        for name in model_names:
            if name in valid_forecasts:
                # è®¡ç®—æƒé‡ï¼ˆMAPEçš„å€’æ•°ï¼‰
                model_mape = mape(val, valid_forecasts[name])
                weight = 1.0 / (model_mape + 1e-6)  # é¿å…é™¤é›¶
                weights.append(weight)
        
        weights = np.array(weights)
        weights = weights / np.sum(weights)  # å½’ä¸€åŒ–æƒé‡
        
        print("æ¨¡å‹æƒé‡:")
        for i, name in enumerate(model_names):
            print(f"  {name}: {weights[i]:.3f}")
        
        ensemble_values = np.average(forecast_array, axis=0, weights=weights)
    elif method == 'median':
        # ä¸­ä½æ•°é›†æˆ
        ensemble_values = np.median(forecast_array, axis=0)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„é›†æˆæ–¹æ³•: {method}")
    
    # åˆ›å»ºTimeSerieså¯¹è±¡
    ensemble_forecast = TimeSeries.from_values(
        ensemble_values,
        start=val.start_time(),
        freq=val.freq
    )
    
    # è®¡ç®—é›†æˆæ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡
    ensemble_mape = mape(val, ensemble_forecast)
    ensemble_rmse = rmse(val, ensemble_forecast)
    ensemble_mae = mae(val, ensemble_forecast)
    
    print(f"\né›†æˆæ¨¡å‹ ({method}) è¯„ä¼°:")
    print(f"  MAPE: {ensemble_mape:.2f}%")
    print(f"  RMSE: {ensemble_rmse:.2f}")
    print(f"  MAE: {ensemble_mae:.2f}")
    
    return ensemble_forecast, ensemble_mape, ensemble_rmse, ensemble_mae

# å¯è§†åŒ–ç»“æœ
def plot_results(train, val, results, ensemble_results=None):
    """å¯è§†åŒ–è®­ç»ƒæ•°æ®ã€éªŒè¯æ•°æ®å’Œé¢„æµ‹ç»“æœ"""
    plt.figure(figsize=(18, 12))
    
    # åˆ›å»ºå­å›¾
    plt.subplot(2, 1, 1)
    
    # ç»˜åˆ¶è®­ç»ƒæ•°æ®å’ŒéªŒè¯æ•°æ®
    train.plot(label='è®­ç»ƒæ•°æ®', color='blue', alpha=0.7)
    val.plot(label='éªŒè¯æ•°æ®', color='green', alpha=0.8, linewidth=2)
    
    # ç»˜åˆ¶æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
    colors = ['red', 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan']
    color_index = 0
    
    for name, result in results.items():
        if result['forecast'] is not None:
            result['forecast'].plot(label=f'{name} (MAPE: {result["mape"]:.1f}%)', 
                                  color=colors[color_index % len(colors)], alpha=0.7)
            color_index += 1
    
    # ç»˜åˆ¶é›†æˆé¢„æµ‹ç»“æœ
    if ensemble_results:
        for method, (forecast, mape_score, _, _) in ensemble_results.items():
            if forecast is not None:
                forecast.plot(label=f'é›†æˆ-{method} (MAPE: {mape_score:.1f}%)', 
                             color='black', linewidth=3, linestyle='--')
    
    plt.title('æ—¶é—´åºåˆ—é¢„æµ‹ç»“æœå¯¹æ¯”', fontsize=14)
    plt.xlabel('æ—¶é—´')
    plt.ylabel('æŒ‡æ ‡å€¼')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    
    # ç¬¬äºŒä¸ªå­å›¾ï¼šè¯¯å·®åˆ†æ
    # plt.subplot(2, 1, 2)
    
    # model_names = []
    # mape_scores = []
    
    # for name, result in results.items():
    #     if result['forecast'] is not None:
    #         model_names.append(name)
    #         mape_scores.append(result['mape'])
    
    # if ensemble_results:
    #     for method, (_, mape_score, _, _) in ensemble_results.items():
    #         if mape_score is not None:
    #             model_names.append(f'é›†æˆ-{method}')
    #             mape_scores.append(mape_score)
    
    # bars = plt.bar(range(len(model_names)), mape_scores, alpha=0.7)
    # plt.xlabel('æ¨¡å‹')
    # plt.ylabel('MAPE (%)')
    # plt.title('æ¨¡å‹æ€§èƒ½å¯¹æ¯” (MAPE)', fontsize=14)
    # plt.xticks(range(len(model_names)), model_names, rotation=45, ha='right')
    # plt.grid(True, alpha=0.3)
    
    # # åœ¨æŸ±çŠ¶å›¾ä¸Šæ˜¾ç¤ºæ•°å€¼
    # for i, bar in enumerate(bars):
    #     height = bar.get_height()
    #     plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,
    #             f'{height:.1f}%', ha='center', va='bottom')
    
    # plt.tight_layout()
    plt.show()

# æ¨¡å‹æ’åå’Œåˆ†æ
def analyze_model_performance(results, ensemble_results=None):
    """åˆ†ææ¨¡å‹æ€§èƒ½å¹¶ç»™å‡ºæ’å"""
    print("\n" + "="*50)
    print("æ¨¡å‹æ€§èƒ½åˆ†ææŠ¥å‘Š")
    print("="*50)
    
    # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„ç»“æœ
    all_results = {}
    
    for name, result in results.items():
        if result['forecast'] is not None:
            all_results[name] = {
                'mape': result['mape'],
                'rmse': result['rmse'],
                'mae': result['mae']
            }
    
    if ensemble_results:
        for method, (_, mape_score, rmse_score, mae_score) in ensemble_results.items():
            if mape_score is not None:
                all_results[f'é›†æˆ-{method}'] = {
                    'mape': mape_score,
                    'rmse': rmse_score,
                    'mae': mae_score
                }
    
    if not all_results:
        print("æ²¡æœ‰å¯ç”¨äºåˆ†æçš„æ¨¡å‹ç»“æœã€‚")
        return

    # æŒ‰MAPEæ’åº
    sorted_results = sorted(all_results.items(), key=lambda x: x[1]['mape'])
    
    print("\næ¨¡å‹æ’å (æŒ‰MAPEä»å°åˆ°å¤§):")
    print("-" * 60)
    print(f"{'æ’å':<4} {'æ¨¡å‹åç§°':<20} {'MAPE':<10} {'RMSE':<10} {'MAE':<10}")
    print("-" * 60)
    
    for i, (name, metrics) in enumerate(sorted_results, 1):
        print(f"{i:<4} {name:<20} {metrics['mape']:<10.2f} {metrics['rmse']:<10.2f} {metrics['mae']:<10.2f}")
    
    # åˆ†ææœ€ä½³æ¨¡å‹
    best_model = sorted_results[0]
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model[0]}")
    print(f"   MAPE: {best_model[1]['mape']:.2f}%")
    print(f"   RMSE: {best_model[1]['rmse']:.2f}")
    print(f"   MAE: {best_model[1]['mae']:.2f}")

# ä¸»å‡½æ•°
def main():
    # ClickHouseè¿æ¥å‚æ•° - è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
    clickhouse_params = {
        'host': '172.17.162.210',
        'port': 30156,
        'user': 'default',
        'password': 'Yh45EWxZnww9JX',
        'database': 'default'
    }
    
    # ç›®æ ‡æ—¥æœŸå’Œè¡¨å - è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
    target_date = '2025-09-13'  # è¦åˆ†æçš„æ—¥æœŸ
    table_name = 'metrics_table'  # å­˜å‚¨æŒ‡æ ‡æ•°æ®çš„è¡¨å
    
    # è¿æ¥åˆ°ClickHouse
    client = connect_clickhouse(**clickhouse_params)
    if not client:
        return
    
    # è¯»å–æ•°æ®
    df = fetch_data_from_clickhouse(client, target_date, table_name)
    if df is None or len(df) == 0:
        print("æ²¡æœ‰è·å–åˆ°æ•°æ®ï¼Œç¨‹åºé€€å‡º")
        return
    
    # å‡†å¤‡æ—¶é—´åºåˆ—
    series = prepare_time_series(df)
    
    # æ‹†åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train, val = split_train_validation(series)
    
    # è®­ç»ƒæ¨¡å‹å¹¶é¢„æµ‹
    print("å¼€å§‹è®­ç»ƒå¤šä¸ªé¢„æµ‹æ¨¡å‹...")
    results, forecasts = train_and_forecast(train, val)
    
    if not results:
        print("æ²¡æœ‰æˆåŠŸè®­ç»ƒä»»ä½•æ¨¡å‹")
        return
    
    # å®ç°é›†æˆå­¦ä¹ 
    print("\nå¼€å§‹é›†æˆå­¦ä¹ ...")
    ensemble_results = {}
    
    # å°è¯•ä¸åŒçš„é›†æˆæ–¹æ³•
    for method in ['average', 'weighted_average', 'median']:
        try:
            ensemble_forecast_result, mape_score, rmse_score, mae_score = ensemble_forecast(
                forecasts, val, method=method
            )
            ensemble_results[method] = (ensemble_forecast_result, mape_score, rmse_score, mae_score)
        except Exception as e:
            print(f"é›†æˆæ–¹æ³• {method} å¤±è´¥: {e}")
    
    # å¯è§†åŒ–ç»“æœ
    plot_results(train, val, results, ensemble_results)
    
    # åˆ†ææ¨¡å‹æ€§èƒ½
    analyze_model_performance(results, ensemble_results)

if __name__ == "__main__":
    main()